<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <title>    "BLEU: a Method for Automatic Evaluation of Machine Translation"
</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta content="This is the homepage of Zeyuan Hu" name="description">
        <meta content="Zeyuan Hu, Zeyuan, zeyuan hu, zeyuan ibm, IBM, Zeyuan IBM, UW Madison, University of Wisconsin Madison, zeyuan wisc, zeyuan IBM, zeyuan federation" name="keywords">
        <meta content="Zeyuan Hu" name="author">
        <link href='https://fonts.googleapis.com/css?family=Gentium+Book+Basic|Merriweather:400,300' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="../../../../../theme/css/cid.css">
        <!-- add font-awesome -->
        <script defer src="../../../../../theme/fa-5/js/all.js"></script>
        <link rel="stylesheet" href="../../../../../theme/academicons/css/academicons.css"/>
        <link href="https://zhu45.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Zeyuan Hu's page Atom Feed" />
        <link href="https://zhu45.org/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Zeyuan Hu's page RSS Feed" />
        <link href="../../../../../theme/images/favicon.ico" rel="icon">
    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->
            <div class="container">
<header class="blog-header">
        <h1 id="site-title"><a href="../../../../.." style="color: black; text-decoration: none">Zeyuan Hu's page</a></h1>
    <p></p>
    <nav>
            <a href="../../../../../about-me.html" style="padding: 10px">ABOUT</a>
            <a href="../../../../../archives/index.html" style="padding: 10px">ARCHIVES</a>
            <a href="../../../../../research.html" style="padding: 10px">RESEARCH</a>
    </nav>
</header>
    <div class="post">
      <header>
            <h1 class="post-title">"BLEU: a Method for Automatic Evaluation of Machine Translation"</h1>
            <div class="panel">
                <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <time datetime="2018-03-28T01:24:00+08:00"> Mar 28, 2018</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="../../../../../tag/natural-language-processing.html">natural language processing</a>
        /
	<a href="../../../../../tag/evaluation-metrics.html">evaluation metrics</a>
        /
	<a href="../../../../../tag/papers.html">papers</a>
    
</footer><!-- /.post-info -->                </div>
            </div>
          <!-- <div class="post-title">"BLEU: a Method for Automatic Evaluation of Machine Translation"</h1></div> -->
          <!-- <div class="post-date"><time datetime="2018-03-28T01:24:00+08:00">Mar 28, 2018</time></div> -->
        </header>
        
        <article>
            <div class="toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-baseline-bleu-metric">The Baseline BLEU Metric</a><ul>
<li><a href="#modified-n-gram-precision">Modified n-gram precision</a></li>
</ul>
</li>
<li><a href="#remarks-on-bleu">Remarks on BLEU</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</div>
<h2 id="introduction">Introduction</h2>
<ul>
<li>
<p>How does one measure translation performance? The central idea: <em>The closer a machine translation is to a professional human translation, the better it is.</em>
Thus requires:</p>
<ul>
<li>a numerical “translation closeness” metric</li>
<li>a corpus of good quality human reference translations</li>
</ul>
</li>
<li>
<p>Fashion the closeness metric after <em>word error rate</em> metric used by the speech recognition community</p>
</li>
<li>
<p>The main idea is to use a weighted average of variable length phrase matches against the reference translations.</p>
</li>
</ul>
<h2 id="the-baseline-bleu-metric">The Baseline BLEU Metric</h2>
<ul>
<li>
<p>Example 1:</p>
<ul>
<li>Candidate 1: It is a guide to action which ensures that the military always obeys the commands of the party.</li>
<li>Candidate 2: It is to insure the troops forever hearing the activity guidebook that party direct.</li>
<li>Reference 1: It is a guide to action that ensures that the military will forever heed Party commands.</li>
<li>Reference 2: It is the guiding principle which guarantees the military forces always being under the command of the Party.</li>
<li>Reference 3: It is the practical guide for the army always to heed the directions of the party.</li>
</ul>
</li>
<li>
<p>Candidate 1 is better than Candidate 2 because Candidate 1 shares many words and phrases with these three reference translations, while Candidate 2 does not.</p>
<ul>
<li>Candidate 1 shares "It is a guide to action" with Reference 1, "which" with Reference 2, "ensures that the military" with Reference 1, 
"always" with References 2 and 3, "commands" with Reference 1, and finally "of the party" with Reference 2 (all ignoring capitalization). 
In contrast, Candidate 2 exhibits far fewer matches, and their extent is less.</li>
</ul>
</li>
<li>
<p>Rank Candidate 1 higher than Candidate 2 simply by comparing n-￼￼gram matches between each candidate translation and the reference translations.</p>
</li>
<li>
<p>The primary programming task for a BLEU implementor is to compare n-grams of the candidate with the n-grams of the reference translation and count the number of matches. These matches are position-independent. The more the matches, the better the candidate translation is.</p>
</li>
</ul>
<h3 id="modified-n-gram-precision">Modified n-gram precision</h3>
<p>We compute unigram matches to illustrate the idea.</p>
<ul>
<li>
<p>Example 2:</p>
<ul>
<li>Candidate: the the the the the the the. </li>
<li>Reference 1: The cat is on the mat. </li>
<li>Reference 2: There is a cat on the mat.</li>
</ul>
</li>
<li>
<p><em>Precision</em> (# candidate translation words (unigrams) which occur in any reference translation / the total number of words in the candidate translation) 
doesn't work: MT systems can overgenerate “reasonable” words, resulting in improbable, but high-precision, translations like Example 2.</p>
</li>
<li>
<p>Intuition: a reference word should be considered exhausted after a matching candidate word is identified. We formalize this intuition as the
<em>modified unigram precision</em>.</p>
</li>
<li>
<p>How to compute <em>modified unigram precision</em>:</p>
<ol>
<li>counts the maximum number of times a word occurs in any single reference translation</li>
<li>one clips the total count of each candidate word by its maximum reference count</li>
<li>adds these clipped counts (i.e., <span class="math">\(\text{Count}_{clip}\)</span>) up, and divides by the total (unclipped) number of candidate words.</li>
</ol>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span class="math">\(\text{Count}_{clip} = \min(\text{Count}, \text{Max_Ref_Count})\)</span>. In other words, one truncates each word’s count, if necessary, to not exceed the largest count observed in any single reference for that word.</p>
</div>
<ul>
<li>
<p>Examples on <em>modified unigram precision</em> calculation:</p>
<ul>
<li>Example 2: modified unigram precision is <span class="math">\(2/7\)</span>, even though its standard unigram precision is <span class="math">\(7/7\)</span>.</li>
<li>
<p>Example 1: Candidate 1 achieves a modified unigram precision of <span class="math">\(17/18\)</span>; whereas Candidate 2 achieves a modified unigram precision of <span class="math">\(8/14\)</span></p>
<p>Let's calculate <span class="math">\(17/18\)</span>. The counts shown below. For word "the", "the" appears 3 times in Candidate 1 and 4 comes from
max(# "the" in ref1, # "the" in ref2, # "the" in ref3) = max(1,4,4). </p>
</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span>| word          | it | is | a | guide | to | action | which | ensures | that | the | miltary | always | obeys | commands | of | party | SUM |
|---------------|----|----|---|-------|----|--------|-------|---------|------|-----|---------|--------|-------|----------|----|-------|-----|
| count         | 1  | 1  | 1 | 1     | 1  | 1      | 1     | 1       | 1    | 3   | 1       | 1      | 1     | 1        | 1  | 1     | 18  |
| Max_Ref_Count | 1  | 1  | 1 | 1     | 1  | 1      | 1     | 1       | 2    | 4   | 1       | 1      | 0     | 1        | 1  | 1     |     |
| Count_clip    | 1  | 1  | 1 | 1     | 1  | 1      | 1     | 1       | 1    | 3   | 1       | 1      | 0     | 1        | 1  | 1     | 17  |
</pre></div>
<ul>
<li>
<p>How to compute Modified n-gram precision (computed similarly for any n): </p>
<ol>
<li>all candidate n-gram counts and their corresponding maximum reference counts are collected. </li>
<li>The candidate counts are clipped by their corresponding reference maximum value, summed, and divided by the total number of candidate n-grams.</li>
</ol>
</li>
<li>
<p>Examples on <em>modified bigram precision</em> calculation:</p>
<ul>
<li>Example 1: Candidate 1 achieves a modified bigram precision of <span class="math">\(10/17\)</span>, whereas the lower quality Candidate 2 achieves a modified bigram precision of <span class="math">\(1/13\)</span>. </li>
<li>Example 2: the (implausible) candidate achieves a modified bigram precision of 0.</li>
</ul>
</li>
<li>
<p>Modified n-gram precision on corpus</p>
<ul>
<li>We first compute the n-gram matches sentence by sentence. Next, we add the clipped n-gram counts for all the candidate sentences and divide by the number of candidate n-grams in the test corpus to compute a modified precision score, <span class="math">\(p_n\)</span>, for the entire test corpus.</li>
</ul>
<p><img alt="modified n-gram precision on corpus" class="img-responsive" src="../../../../../images/bleu-corpus.png"/></p>
</li>
<li>
<p>We want to combine all n-gram precision on corpus (i.e., <span class="math">\(n=1,2,3,4\)</span>) together into a single number metric. the modified n-gram precision decays roughly exponentially with n: the modified unigram precision is much larger than the modified bigram precision which in turn is much bigger than the modified trigram precision. BLEU uses the geometric mean of the modified n-gram precisions.</p>
</li>
<li>
<p>Modified n-gram precision alone fails to enforce the proper translation length. Candidate translations longer than their references are already penalized by the modified n-gram precision measure. However, candidate translations shorter than their references are not penalized.</p>
<ul>
<li>
<p>Example 3:</p>
<ul>
<li>Candidate: of the</li>
<li>Reference 1: It is a guide to action that ensures that the military will forever heed Party commands.</li>
<li>Reference 2: It is the guiding principle which guarantees the military forces always being under the command of the Party.</li>
<li>Reference 3: It is the practical guide for the army always to heed the directions of the party.</li>
</ul>
</li>
<li>
<p>Because this candidate is so short compared to the proper length, one expects to find inflated precisions: the modified unigram precision is 2/2, and the modified bigram precision is 1/1.</p>
</li>
</ul>
</li>
<li>
<p>Traditional recall is not a good measure to enforce proper length translation:</p>
<ul>
<li>
<p>Example 4:</p>
<ul>
<li>Candidate 1: I always invariably perpetually do.</li>
<li>Candidate 2: I always do.</li>
<li>Reference 1: I always do.</li>
<li>Reference 2: I invariably do. </li>
<li>Reference 3: I perpetually do.</li>
</ul>
</li>
<li>
<p>The first candidate recalls more words from the references, but is obviously a poorer translation than the second candidate</p>
</li>
</ul>
</li>
<li>
<p>Sentence ￼￼￼￼￼￼￼brevity penalty</p>
<ul>
<li>We wish to make the brevity penalty 1.0 when the candidate’s length is the same as any reference translation’s length.</li>
<li>if there are three references with lengths 12, 15, and 17 words and the candidate translation is a terse 12 words, we want the brevity penalty to be 1. </li>
<li>We call the closest reference sentence length the “<em>best match length</em>.”</li>
<li>we compute the brevity penalty over the entire corpus to al- low some freedom at the sentence level.</li>
</ul>
</li>
<li>
<p>Compute sentence brevity penalty</p>
<ol>
<li>Compute the test corpus’ effective reference length, <span class="math">\(r\)</span>, by summing the best match lengths for each candidate sentence in the corpus. </li>
<li>We choose the brevity penalty to be a decaying exponential in <span class="math">\(r/c\)</span>, where <span class="math">\(c\)</span> is the total length of the candidate translation corpus.</li>
</ol>
</li>
<li>
<p>Put everything together to calculate BLEU</p>
<p>We take the geometric mean of the test corpus’ modified precision scores and then multiply the result by an exponential brevity penalty factor.
We first compute the geometric average of the modified n-gram precisions, <span class="math">\(p_n\)</span>, using n-grams up to length <span class="math">\(N\)</span> and positive weights <span class="math">\(w_n\)</span> summing to one.
Next, let <span class="math">\(c\)</span> be the length of the candidate translation and <span class="math">\(r\)</span> be the effective reference corpus length. We compute the brevity penalty BP,</p>
<p><img alt="BLEU calculation" class="img-responsive" src="../../../../../images/bleu-calc.png"/> </p>
</li>
</ul>
<h2 id="remarks-on-bleu">Remarks on BLEU</h2>
<ul>
<li>
<p>This sort of modified n-gram precision scoring captures two aspects of translation: adequacy and fluency:</p>
<p>A translation using the same words (1-grams) as in the references tends to satisfy adequacy. The longer n-gram matches account for fluency. </p>
</li>
<li>
<p>BLEU only needs to match human judgment when averaged over a test corpus; scores on individual sentences will often vary from human judgments.
(For example, a system which produces the fluent phrase “East Asian economy” is penalized heavily on the longer n-gram precisions if all the references happen to read “economy of East Asia.”)</p>
</li>
<li>
<p>The BLEU metric ranges from 0 to 1. Few translations will attain a score of 1 unless they are identical to a reference translation</p>
</li>
<li>the more reference translations per sentence there are, the higher the score is.</li>
<li>We may use a big test corpus with a single reference translation, provided that the translations are not all from the same translator.</li>
<li>BLEU has shown good performance for corpus-level comparisons over which a high number of n-gram matches exist. However, at a sentence-level the
n-gram matches for higher n rarely occur. As a result, BLEU performs poorly when comparing individual sentences.</li>
<li><a href="https://www.cs.utexas.edu/~mooney/cs388/slides/mt.ppt">Mooney's slides on MT</a> has nice illustration of modified bigram precision
calculation</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.aclweb.org/anthology/P02-1040.pdf">Bleu: a method for automatic evaluation of machine translation</a></li>
<li><a href="https://arxiv.org/pdf/1504.00325.pdf">Microsoft COCO Captions: Data Collection and Evaluation Server</a></li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
        </article>

        <footer>
          <!-- <p>This entry is posted in <a href="../../../../../category/nlp.html">NLP</a>.</p> -->
          <!-- <a href="../../../../../donate.html" class="button">Donate</a> -->
          <a href="https://paypal.me/zhu45?locale.x=en_US">paypal.me</a>
        </footer>
        
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'zhu45-org';
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

    </div>


<script>
   function topFunction() {
       document.body.scrollTop = 0;
       document.documentElement.scrollTop = 0;
   }
</script>

<footer class="blog-footer">
    <div id="copyright">
      Copyright (c) 2015-2021 <a href="../../../../../about-me.html">Zeyuan Hu</a>
    </div>
    <div id="archive">
      <a href="javascript:topFunction();">Back to top</a>
    </div>
</footer>
            </div>
<script>
    var _gaq=[['_setAccount','UA-37565522-2'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
    </body>
</html>