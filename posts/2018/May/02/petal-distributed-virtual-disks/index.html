<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-44FB4FMFCD"></script>
        <script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());

              gtag('config', 'G-44FB4FMFCD');
        </script>
        <meta charset="utf-8">
        <title>    "Petal: Distributed Virtual Disks"
</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta content="This is the homepage of Zeyuan Hu" name="description">
        <meta content="Zeyuan Hu, Zeyuan, zeyuan hu, zeyuan ibm, IBM, Zeyuan IBM, UW Madison, University of Wisconsin Madison, zeyuan wisc, zeyuan IBM, zeyuan federation, Zeyuan UT-Austin, Zeyuan Texas, Zeyuan University of Texas at Austin, Zeyuan Amazon, Zeyuan Microsoft Research, Zeyuan Microsoft" name="keywords">
        <meta content="Zeyuan Hu" name="author">
        <link href='https://fonts.googleapis.com/css?family=Gentium+Book+Basic|Merriweather:400,300' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="../../../../../theme/css/cid.css">
        <!-- add font-awesome -->
        <script defer src="../../../../../theme/fa-5/js/all.js"></script>
        <link rel="stylesheet" href="../../../../../theme/academicons/css/academicons.css"/>
        <link href="https://zhu45.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Zeyuan Hu's page Atom Feed" />
        <link href="https://zhu45.org/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Zeyuan Hu's page RSS Feed" />
        <link href="../../../../../theme/images/favicon.ico" rel="icon">
    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->
            <div class="container">
<header class="blog-header">
        <h1 id="site-title"><a href="../../../../.." style="color: black; text-decoration: none">Zeyuan Hu's page</a></h1>
    <p></p>
    <nav>
            <a href="../../../../../about-me.html" style="padding: 10px">ABOUT</a>
            <a href="../../../../../archives/index.html" style="padding: 10px">ARCHIVES</a>
            <a href="../../../../../research.html" style="padding: 10px">RESEARCH</a>
    </nav>
</header>
    <div class="post">
      <header>
            <h1 class="post-title">"Petal: Distributed Virtual Disks"</h1>
            <div class="panel">
                <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <time datetime="2018-05-02T02:20:00+08:00"> May 02, 2018</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="../../../../../tag/papers.html">papers</a>
        /
	<a href="../../../../../tag/distributed-systems.html">distributed systems</a>
        /
	<a href="../../../../../tag/storage.html">storage</a>
    
</footer><!-- /.post-info -->                </div>
            </div>
          <!-- <div class="post-title">"Petal: Distributed Virtual Disks"</h1></div> -->
          <!-- <div class="post-date"><time datetime="2018-05-02T02:20:00+08:00">May 02, 2018</time></div> -->
        </header>
        
        <article>
            <div class="toc">
<ul>
<li><a href="#problem">Problem</a></li>
<li><a href="#system-design">System design</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</div>
<h2 id="problem">Problem</h2>
<p>Design a distributed storage system that is easy-to-use and easy-to-administer.</p>
<ul>
<li>
<p>Easy-to-use:</p>
<ul>
<li>Simple Interface</li>
<li>availability / fault tolerance</li>
<li>transparency</li>
<li>consistency</li>
</ul>
</li>
<li>
<p>Easy-to-administer:</p>
<ul>
<li>crash recovery (no manual needed)</li>
<li>scability (scale up with the workloads without performance degration)</li>
<li>add / remove nodes</li>
<li>load balancing</li>
<li>monitoring</li>
</ul>
</li>
</ul>
<h2 id="system-design">System design</h2>
<p><img alt="petal client view" class="img-responsive" src="/images/petal-client-view.png"/></p>
<ul>
<li>Petal consists of a collection of network-connected servers that cooperatively manage a pool of physical disks</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Petal is different from distributed file system (NFS) in the sense that clients in NFS can directly access the server physical disks. However, Petal hides the physical resources through the layer of abstraction. The benefits of this abstraction:
- scale to a large size and reliable data storage over in long run
- support heterogeneous clients and client applications (e.g., different file systems) (Figure 2)</p>
</div>
<p><img alt="petal physical view" class="img-responsive" src="/images/petal-physical-view.png"/></p>
<p><img alt="petal prototype" class="img-responsive" src="/images/petal-prototype.png"/></p>
<ul>
<li>Clients (FS or DB) view Petal as a collection of <em>virtual disks</em> (Figure 1)</li>
<li>Disk-like Interface: data are read and written to Petal virtual disks in blocks (i.e., the basic tranfer unit) through RPC</li>
</ul>
<p><img alt="petal server modules" class="img-responsive" src="/images/petal-server-modules.png"/></p>
<ul>
<li>
<p>Software modules:</p>
<ul>
<li>liveness module:<ul>
<li>ensures that all servers in the system will agree on the operational status (running or crashed) of each other</li>
<li>majority consensus (Paxos) + heatbeat</li>
</ul>
</li>
<li>global state module:<ul>
<li>include information: current members of system + currently supported virtual disks</li>
<li>consistently maintain information -&gt; Paxos</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Virtual disk address -&gt; physical disk address:</p>
<ul>
<li>virtual disk address form: <virtual-disk-identifer, offset=""></virtual-disk-identifer,></li>
<li>virtual disk identifier -&gt; global map identifier (via. virtual disk directory)</li>
<li>global map identifier decides the server for translating offset</li>
<li>global map identifier &amp; offset -&gt; disk-identifier, disk-offset (via. phyiscal map on each server)</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Separation of the translation data structures into global and local physical maps:
- keep bulk of mapping information local (minimizes the information kept globally, which is replicated and thus
hard to update)</p>
</div>
<ul>
<li>
<p>Global map:</p>
<ul>
<li>One global map per virtual disk that specifies the tuple of servers spanned by the virtual disk</li>
<li>immutable -&gt; new global map if change virtual disk's tuple of server / redundancy scheme</li>
</ul>
</li>
<li>
<p>Backup:</p>
<ul>
<li>copy-on-write to create exact copy of a virtual disk at a specified point in time</li>
<li>Use epoch-number as version number</li>
<li>Create a snapshot consistent with client application level requires pauseing the application</li>
<li>Can also use "crash-consistent" snapshot and later recovered by the application-specific recovery protocol</li>
</ul>
</li>
<li>
<p>Add server:</p>
<ul>
<li>add to the membership of the Petal</li>
<li>adjust liveness module to incorporate new server</li>
<li>virtual disk reconfiguration (reconfigure existing virtual disks to use new resources -&gt; data redistribution)</li>
</ul>
</li>
<li>
<p>Virtual disk reconfiguration (data redistribution):</p>
<ul>
<li>data redistribution can take hours to finish (won't compete network &amp; disk traffic with write/read serving)</li>
<li>Basic steps:<ul>
<li>create a new global map with redundancy scheme + server mapping</li>
<li>change all virtual disk directory entries that refer to the old global map to refer to the new one</li>
<li>redistribute data to servers according to new global map<ul>
<li>start with the most recent epoch that have not yet been moved (not return old data when READ)</li>
<li>need to read/write during redistribution:<ul>
<li>READ: try the new global map first, then the old global map</li>
<li>WRITE: use new global map</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Refinement:<ul>
<li>don't need to change server mapping for an entire virtual disk before any data is moved (-&gt; READ miss given new global map)</li>
<li>sol:<ul>
<li>break virtual disk's address into: old, new, fenced</li>
<li>Requests to old/new use old/new global maps</li>
<li>Use "Basic steps" for fenced only</li>
<li>Once we have relocated everything in the fenced region, it becomes new region and we fence another part of the old region</li>
</ul>
</li>
<li>tricks:<ul>
<li>keep the relative size of the fenced region small</li>
<li>construct fenced region using small non-contiguous ranges distributed throughout the virtual disk (not single
contiguous region b/c fenced region may be heavily used)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img alt="chained-declustering" class="img-responsive" src="/images/chained-declustering.png"/></p>
<ul>
<li>
<p>Data access and recovery:</p>
<ul>
<li>Use chained-declustered data access and recovery modules (chained-declustering):<ul>
<li>Two copies of each block of data are always stored on neighboring servers<ul>
<li>Server 1 fails, servers 0 and 2 will share server 1's real load; server 3 will not have load increase</li>
<li>Can offload load to a server to neighboring servers</li>
<li>similar to consistent hashing</li>
</ul>
</li>
</ul>
</li>
<li>Dynamic load balancing scheme:<ul>
<li>each client keep tracks of the number of requests it has pending at each server and always sends read requests to the
server with the short queue length</li>
<li>Works for most of requests are from a few clients (not for many clients with occassional requests)</li>
</ul>
</li>
<li>Tolerate site failures:<ul>
<li>all the even-numbered servers at one site and all the odd-numbered servers at another site (less reliable
since data on a given server is replicate on neighboring only)</li>
</ul>
</li>
<li>one of two copies of each data block is denoted the primary. Rest are secondary.</li>
<li>READ:<ul>
<li>Read from either primary or secondary</li>
<li>Clients retry on failure</li>
</ul>
</li>
<li>WRITE:<ul>
<li>Use primary always</li>
<li>Mask the data as busy. Simultaneously sends write requests to its local copy and the secondary copy. When both requests complete, the busy bit is cleared and the client that issued the request is sent a status code indicating the success or failure of the operation.</li>
<li>Optimization:<ul>
<li>write-ahead-logging with group commits (batch the busy bits update)</li>
<li>cache the busy bits (avoid disk I/O to set busy bits)</li>
</ul>
</li>
<li>Primary fail:<ul>
<li>the secondary marks the data element as stale on stable storage before writing it to its local disk. The server containing the primary copy will eventually have to bring all data elements marked stale up-to-date during its recovery process.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Petal's limitation:</p>
<ul>
<li>High requirement to the network (use digital ATM Network)</li>
<li>Petal's use of the virtual disk abstraction adds an additional level of overhead, and can prevent application-specific disk optimizations that rely on careful placement of data.    </li>
</ul>
</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="http://pages.cs.wisc.edu/~remzi/Classes/739/Fall2017/Papers/petal96.pdf">Petal: Distributed Virtual Disks </a></li>
</ul>
        </article>

        <footer>
          <!-- <p>This entry is posted in <a href="../../../../../category/system.html">system</a>.</p> -->
          <!-- <a href="../../../../../donate.html" class="button">Donate</a> -->
          <a href="https://paypal.me/zhu45?locale.x=en_US">paypal.me</a>
        </footer>
        
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'zhu45-org';
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

    </div>


<script>
   function topFunction() {
       document.body.scrollTop = 0;
       document.documentElement.scrollTop = 0;
   }
</script>

<footer class="blog-footer">
    <div id="copyright">
      Copyright (c) 2015-2022 <a href="../../../../../about-me.html">Zeyuan Hu</a>
    </div>
    <div id="archive">
      <a href="javascript:topFunction();">Back to top</a>
    </div>
</footer>
            </div>
<script>
    var _gaq=[['_setAccount','UA-37565522-2'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
    </body>
</html>